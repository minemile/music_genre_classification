{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "import librosa\n",
    "import numpy as np\n",
    "import librosa.display\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from server.database_wrapper import PostgresqlWrapper\n",
    "from server.utils import Util\n",
    "from feature_extractor import FeatureExtractor\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Грузим датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = list()\n",
    "genre_list = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genres=['classical', 'metal', 'blues', 'hiphop', 'disco', 'pop', 'rock', 'country', 'reggae', 'jazz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getData(where_to, genre_list, genre, range_tuple):\n",
    "    for i in tqdm(range(range_tuple)):\n",
    "        if i < 10:\n",
    "            path = \"../../\" + genre + \"/\" + genre + \".0000\" + str(i) + \".au\"        \n",
    "        else:\n",
    "            path = \"../../\" + genre + \"/\" + genre + \".000\" + str(i) + \".au\"\n",
    "        \n",
    "        song = librosa.load(path)\n",
    "        where_to.append(song[0])\n",
    "        genre_list.append(genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:00<00:00,  1.61it/s]\n",
      "100%|██████████| 100/100 [00:57<00:00,  1.81it/s]\n",
      "100%|██████████| 100/100 [00:54<00:00,  1.90it/s]\n",
      "100%|██████████| 100/100 [00:52<00:00,  1.96it/s]\n",
      "100%|██████████| 100/100 [00:55<00:00,  1.51it/s]\n",
      "100%|██████████| 100/100 [00:56<00:00,  1.66it/s]\n",
      "100%|██████████| 100/100 [01:01<00:00,  1.77it/s]\n",
      "100%|██████████| 100/100 [00:56<00:00,  1.81it/s]\n",
      "100%|██████████| 100/100 [00:56<00:00,  1.78it/s]\n",
      "100%|██████████| 100/100 [01:00<00:00,  1.26it/s]\n"
     ]
    }
   ],
   "source": [
    "for genre in genres:\n",
    "    getData(data, genre_list, genre, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Извлекаем фичи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = FeatureExtractor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got rmse data for 0 songs\n",
      "Got rmse data for 50 songs\n",
      "Got rmse data for 100 songs\n",
      "Got rmse data for 150 songs\n",
      "Got rmse data for 200 songs\n",
      "Got rmse data for 250 songs\n",
      "Got rmse data for 300 songs\n",
      "Got rmse data for 350 songs\n",
      "Got rmse data for 400 songs\n",
      "Got rmse data for 450 songs\n",
      "Got rmse data for 500 songs\n",
      "Got rmse data for 550 songs\n",
      "Got rmse data for 600 songs\n",
      "Got rmse data for 650 songs\n",
      "Got rmse data for 700 songs\n",
      "Got rmse data for 750 songs\n",
      "Got rmse data for 800 songs\n",
      "Got rmse data for 850 songs\n",
      "Got rmse data for 900 songs\n",
      "Got rmse data for 950 songs\n"
     ]
    }
   ],
   "source": [
    "low_energy = extractor.generate_energy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got flux data for 0 songs\n",
      "Got flux data for 50 songs\n",
      "Got flux data for 100 songs\n",
      "Got flux data for 150 songs\n",
      "Got flux data for 200 songs\n",
      "Got flux data for 250 songs\n",
      "Got flux data for 300 songs\n",
      "Got flux data for 350 songs\n",
      "Got flux data for 400 songs\n",
      "Got flux data for 450 songs\n",
      "Got flux data for 500 songs\n",
      "Got flux data for 550 songs\n",
      "Got flux data for 600 songs\n",
      "Got flux data for 650 songs\n",
      "Got flux data for 700 songs\n",
      "Got flux data for 750 songs\n",
      "Got flux data for 800 songs\n",
      "Got flux data for 850 songs\n",
      "Got flux data for 900 songs\n",
      "Got flux data for 950 songs\n"
     ]
    }
   ],
   "source": [
    "flux = extractor.generate_flux()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got rolloff data for 0 songs\n",
      "Got rolloff data for 50 songs\n",
      "Got rolloff data for 100 songs\n",
      "Got rolloff data for 150 songs\n",
      "Got rolloff data for 200 songs\n",
      "Got rolloff data for 250 songs\n",
      "Got rolloff data for 300 songs\n",
      "Got rolloff data for 350 songs\n",
      "Got rolloff data for 400 songs\n",
      "Got rolloff data for 450 songs\n",
      "Got rolloff data for 500 songs\n",
      "Got rolloff data for 550 songs\n",
      "Got rolloff data for 600 songs\n",
      "Got rolloff data for 650 songs\n",
      "Got rolloff data for 700 songs\n",
      "Got rolloff data for 750 songs\n",
      "Got rolloff data for 800 songs\n",
      "Got rolloff data for 850 songs\n",
      "Got rolloff data for 900 songs\n",
      "Got rolloff data for 950 songs\n"
     ]
    }
   ],
   "source": [
    "rolloff = extractor.generate_rolloff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got rhythm data for 0 songs\n",
      "Got rhythm data for 50 songs\n",
      "Got rhythm data for 100 songs\n",
      "Got rhythm data for 150 songs\n",
      "Got rhythm data for 200 songs\n",
      "Got rhythm data for 250 songs\n",
      "Got rhythm data for 300 songs\n",
      "Got rhythm data for 350 songs\n",
      "Got rhythm data for 400 songs\n",
      "Got rhythm data for 450 songs\n",
      "Got rhythm data for 500 songs\n",
      "Got rhythm data for 550 songs\n",
      "Got rhythm data for 600 songs\n",
      "Got rhythm data for 650 songs\n",
      "Got rhythm data for 700 songs\n",
      "Got rhythm data for 750 songs\n",
      "Got rhythm data for 800 songs\n",
      "Got rhythm data for 850 songs\n",
      "Got rhythm data for 900 songs\n",
      "Got rhythm data for 950 songs\n"
     ]
    }
   ],
   "source": [
    "rhythm = extractor.generate_rhythm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got mfcc for 0 songs\n",
      "Got mfcc for 50 songs\n",
      "Got mfcc for 100 songs\n",
      "Got mfcc for 150 songs\n",
      "Got mfcc for 200 songs\n",
      "Got mfcc for 250 songs\n",
      "Got mfcc for 300 songs\n",
      "Got mfcc for 350 songs\n",
      "Got mfcc for 400 songs\n",
      "Got mfcc for 450 songs\n",
      "Got mfcc for 500 songs\n",
      "Got mfcc for 550 songs\n",
      "Got mfcc for 600 songs\n",
      "Got mfcc for 650 songs\n",
      "Got mfcc for 700 songs\n",
      "Got mfcc for 750 songs\n",
      "Got mfcc for 800 songs\n",
      "Got mfcc for 850 songs\n",
      "Got mfcc for 900 songs\n",
      "Got mfcc for 950 songs\n"
     ]
    }
   ],
   "source": [
    "mfcc_means = extractor.generate_mfcc(n_mfcc=20, sr=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got zero_cross_rate for 0 songs\n",
      "Got zero_cross_rate for 50 songs\n",
      "Got zero_cross_rate for 100 songs\n",
      "Got zero_cross_rate for 150 songs\n",
      "Got zero_cross_rate for 200 songs\n",
      "Got zero_cross_rate for 250 songs\n",
      "Got zero_cross_rate for 300 songs\n",
      "Got zero_cross_rate for 350 songs\n",
      "Got zero_cross_rate for 400 songs\n",
      "Got zero_cross_rate for 450 songs\n",
      "Got zero_cross_rate for 500 songs\n",
      "Got zero_cross_rate for 550 songs\n",
      "Got zero_cross_rate for 600 songs\n",
      "Got zero_cross_rate for 650 songs\n",
      "Got zero_cross_rate for 700 songs\n",
      "Got zero_cross_rate for 750 songs\n",
      "Got zero_cross_rate for 800 songs\n",
      "Got zero_cross_rate for 850 songs\n",
      "Got zero_cross_rate for 900 songs\n",
      "Got zero_cross_rate for 950 songs\n"
     ]
    }
   ],
   "source": [
    "zcrs = extractor.generate_zero_crossing_rate(None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got centroid data for 0 songs\n",
      "Got centroid data for 50 songs\n",
      "Got centroid data for 100 songs\n",
      "Got centroid data for 150 songs\n",
      "Got centroid data for 200 songs\n",
      "Got centroid data for 250 songs\n",
      "Got centroid data for 300 songs\n",
      "Got centroid data for 350 songs\n",
      "Got centroid data for 400 songs\n",
      "Got centroid data for 450 songs\n",
      "Got centroid data for 500 songs\n",
      "Got centroid data for 550 songs\n",
      "Got centroid data for 600 songs\n",
      "Got centroid data for 650 songs\n",
      "Got centroid data for 700 songs\n",
      "Got centroid data for 750 songs\n",
      "Got centroid data for 800 songs\n",
      "Got centroid data for 850 songs\n",
      "Got centroid data for 900 songs\n",
      "Got centroid data for 950 songs\n"
     ]
    }
   ],
   "source": [
    "cent = extractor.generate_centoid_meanstd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zcrs = extractor.generate_zero_crossing_rate(None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вводим названия фичей\n",
    "\n",
    "list_names = [\"mfcc_mean_\" + str(i) for i in range(1,21)]\n",
    "list_names.append(\"std_mfcc\")\n",
    "list_names.append(\"zero_cros_mean\")\n",
    "list_names.append(\"zero_cros_std\")\n",
    "list_names.append(\"cent_mean\")\n",
    "list_names.append(\"cent_std\")\n",
    "list_names.append(\"tempo_static\")\n",
    "list_names.append(\"tempo_mean\")\n",
    "list_names.append(\"tempo_std\")\n",
    "list_names.append(\"num_tempo_changes\")\n",
    "list_names.append(\"rolloff_mean\")\n",
    "list_names.append(\"rolloff_std\")\n",
    "list_names.append(\"flux_mean\")\n",
    "list_names.append(\"flux_std\")\n",
    "list_names.append(\"energy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучаем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.hstack((mfcc_means, zcrs, cent, rhythm, rolloff, flux, low_energy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Исключаем плохие жанры\n",
    "mask = (np.array(genre_list) != 'country') & (np.array(genre_list) != 'jazz') & (np.array(genre_list) != 'reggae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_genre_list = np.array(genre_list)[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for xgboost. Encode genres. Train/test split\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(np.array(new_genre_list))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalization\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_scaled_train = scaler.transform(X_train)\n",
    "X_scaled_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_scaled_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_scaled_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.102041\teval-merror:0.404762\n",
      "[1]\ttrain-merror:0.046939\teval-merror:0.328571\n",
      "[2]\ttrain-merror:0.034694\teval-merror:0.357143\n",
      "[3]\ttrain-merror:0.026531\teval-merror:0.357143\n",
      "[4]\ttrain-merror:0.016327\teval-merror:0.357143\n",
      "[5]\ttrain-merror:0.008163\teval-merror:0.328571\n",
      "[6]\ttrain-merror:0.004082\teval-merror:0.309524\n",
      "[7]\ttrain-merror:0.004082\teval-merror:0.290476\n",
      "[8]\ttrain-merror:0.004082\teval-merror:0.295238\n",
      "[9]\ttrain-merror:0.002041\teval-merror:0.285714\n"
     ]
    }
   ],
   "source": [
    "# Xgboost training\n",
    "param = {'objective': \"multi:softmax\", \"num_class\": np.unique(y_train).size}\n",
    "evallist = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "bst = xgb.train(param, dtrain, evals=evallist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "  classical       0.70      0.70      0.70        30\n",
      "      metal       0.90      0.93      0.92        30\n",
      "      blues       0.70      0.47      0.56        30\n",
      "     hiphop       0.71      0.67      0.69        30\n",
      "      disco       0.70      0.87      0.78        30\n",
      "        pop       0.76      0.83      0.79        30\n",
      "       rock       0.52      0.53      0.52        30\n",
      "\n",
      "avg / total       0.71      0.71      0.71       210\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anton/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 7, does not match size of target_names, 10\n",
      "  .format(len(labels), len(target_names))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, bst.predict(dtest), target_names=['classical', 'metal', 'blues', 'hiphop', 'disco', 'pop', 'rock', 'country', 'reggae', 'jazz']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=50, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(kernel='rbf', C=50)\n",
    "svm.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "  classical       0.79      0.73      0.76        30\n",
      "      metal       0.91      1.00      0.95        30\n",
      "      blues       0.75      0.60      0.67        30\n",
      "     hiphop       0.78      0.93      0.85        30\n",
      "      disco       0.90      0.93      0.92        30\n",
      "        pop       0.82      0.77      0.79        30\n",
      "       rock       0.67      0.67      0.67        30\n",
      "\n",
      "avg / total       0.80      0.80      0.80       210\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anton/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 7, does not match size of target_names, 10\n",
      "  .format(len(labels), len(target_names))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, svm.predict(X_scaled_test), target_names=['classical', 'metal', 'blues', 'hiphop', 'disco', 'pop', 'rock', 'country', 'reggae', 'jazz']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "  classical       0.74      0.57      0.64        30\n",
      "      metal       0.97      0.97      0.97        30\n",
      "      blues       0.50      0.43      0.46        30\n",
      "     hiphop       0.78      0.60      0.68        30\n",
      "      disco       0.64      0.90      0.75        30\n",
      "        pop       0.73      0.80      0.76        30\n",
      "       rock       0.45      0.50      0.48        30\n",
      "\n",
      "avg / total       0.69      0.68      0.68       210\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anton/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 7, does not match size of target_names, 10\n",
      "  .format(len(labels), len(target_names))\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=50, )\n",
    "clf.fit(X_scaled_train, y_train)\n",
    "print(classification_report(y_test, clf.predict(X_scaled_test), target_names=['classical', 'metal', 'blues', 'hiphop', 'disco', 'pop', 'rock', 'country', 'reggae', 'jazz']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 150 candidates, totalling 450 fits\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(svm, {\"C\": np.logspace(0,2), \"kernel\": [\"poly\", \"rbf\", \"sigmoid\"]}, n_jobs = -1, verbose=True)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'n_estimators': [10, 20, 50, 80, 100, 200, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5)\n",
    "CV_rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'n_estimators': [10, 20, 50, 80, 100, 200, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8,10,14,20,25,30,40,50],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5)\n",
    "CV_rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
